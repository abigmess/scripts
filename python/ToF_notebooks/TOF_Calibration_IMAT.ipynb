{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I write the routine for TOF spectrum calibration\n",
    "\n",
    "        What it should be done:\n",
    "        - read the theoretical spectrum\n",
    "        - read the calibration sample\n",
    "        - be able to convert from TOF to lambda and back\n",
    "        - calculate T0 and deltaL, which are the results of the calibration \n",
    "        \n",
    "        time to lambda convertion:\n",
    "            lambda = h/mL (t-t0)\n",
    "            where:lambda = wavelength [A] (A=0.1nm = 1e-10m)\n",
    "                    h = Planck's constant: 6.62607004 Ã— 10-34 m^2 kg / s\n",
    "                    m = Neutron mass [kg]: 1.674 927 471 x 10-27 kg \n",
    "                    L = total flight path [m]\n",
    "                    t = time of flight [s]\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:26:35.631764Z",
     "start_time": "2019-01-28T11:26:32.181324Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carminati_c/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import os, fnmatch\n",
    "from os import listdir\n",
    "%matplotlib inline\n",
    "import scipy.signal\n",
    "print(scipy.__version__)\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import savgol_filter\n",
    "import AdvancedBraggEdgeFitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:26:43.156108Z",
     "start_time": "2019-01-28T11:26:43.152333Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constant values\n",
    "h=6.62607004e-34 #Planck constant [m^2 kg / s]\n",
    "m=1.674927471e-27 #Neutron mass [kg]\n",
    "t0=0\n",
    "L= 56.4 #[m]\n",
    "dL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:20.474457Z",
     "start_time": "2019-01-28T11:24:20.469453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tof2l(tof):\n",
    "    l=h/m*(tof-t0)/(L+dL)/1e-10\n",
    "    return l\n",
    "\n",
    "def l2tof(l):\n",
    "    tof=t0+(l*1e-10)*(L+dL)*m/h\n",
    "    return tof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:21.414840Z",
     "start_time": "2019-01-28T11:24:21.261232Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mylambda = np.genfromtxt('lambda.txt',usecols=0)\n",
    "myspectrum = np.genfromtxt('alpha.txt',usecols=0)\n",
    "\n",
    "# print(mylambda)\n",
    "mytof = l2tof(mylambda)\n",
    "relambda = tof2l(mytof)\n",
    "plt.plot(mylambda, myspectrum/max(myspectrum))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:27.382285Z",
     "start_time": "2019-01-28T11:24:27.231245Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the calibration spectrum from file\n",
    "mycaltof = np.genfromtxt('/media/carminati_c/Elements/RB1820231/02_HighStats_Radio_1hruns/samples_after_reboot_OC_Fiji/IMAT00010420_HighStats_Radio_1hruns_000_Spectra.txt', usecols=0)\n",
    "myhist = np.genfromtxt('/media/carminati_c/Elements/RB1820231/02_HighStats_Radio_1hruns/samples_after_reboot_OC_Fiji/IMAT00010420_HighStats_Radio_1hruns_000_Spectra.txt', usecols=1) #this is the cumulative histogram of the raw data (before the overlap correction)\n",
    "\n",
    "plt.plot(mycaltof,myhist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:27.992564Z",
     "start_time": "2019-01-28T11:24:27.989367Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the calibration datasets:\n",
    "pathdata =\"/media/carminati_c/Elements/RB1820231/02_HighStats_Radio_1hruns/samples_after_reboot_OC_Fiji/\"\n",
    "pathOB = \"/media/carminati_c/Elements/RB1820231/02_HighStats_Radio_1hruns/flat_after_reboot_OC_Fiji/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:29.081680Z",
     "start_time": "2019-01-28T11:24:29.069239Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myfiles = fnmatch.filter(listdir(pathdata),'*.fits')\n",
    "coll_files = sorted(myfiles)\n",
    "print(coll_files[504])\n",
    "print(coll_files[505])\n",
    "print(coll_files[506])\n",
    "\n",
    "obfiles = fnmatch.filter(listdir(pathOB),'*.fits') # here there are several OB folders\n",
    "coll_ob = sorted(obfiles)\n",
    "print(coll_ob[504])\n",
    "print(coll_ob[505])\n",
    "print(coll_ob[506])\n",
    "# print(sorted(obfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:17:47.718347Z",
     "start_time": "2019-01-28T11:17:47.715668Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I don't have repeated measurement for the OB for the cal sample\n",
    "\n",
    "# # normalized_sample = np.zeros([512,512,len(coll_files)])\n",
    "# obsubfiles = [None]*len(obfiles)\n",
    "\n",
    "# for i in range(0, len(obfiles)):\n",
    "# #     print(obfiles[i])\n",
    "#     obsubfiles[i]= sorted(fnmatch.filter(listdir(pathOB+obfiles[i]+'/Corrected'),'*.fits')) \n",
    "\n",
    "# print(obsubfiles[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:33.197305Z",
     "start_time": "2019-01-28T11:24:32.994404Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roi_cal = np.array([6,16,57,500])\n",
    "filename = pathdata + coll_files[0]\n",
    "im = fits.open(filename)\n",
    "# plt.imshow(im[0].data)\n",
    "plt.imshow(im[0].data[roi_cal[1]:roi_cal[3],roi_cal[0]:roi_cal[2]]) #this is the area that I want to study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:42.480750Z",
     "start_time": "2019-01-28T11:24:34.021999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal_spectrum = np.zeros(len(coll_files))\n",
    "cal_ob = np.zeros(len(coll_files))\n",
    "ori_hist = np.zeros(len(coll_files))\n",
    "\n",
    "for i in range(0, len(coll_files)):\n",
    "    \n",
    "    curr_img = (fits.open(pathdata+coll_files[i])[0].data[roi_cal[1]:roi_cal[3],roi_cal[0]:roi_cal[2]]).astype(float)\n",
    "    curr_ob =(fits.open(pathOB+coll_ob[i])[0].data[roi_cal[1]:roi_cal[3],roi_cal[0]:roi_cal[2]]).astype(float)\n",
    "    cal_spectrum[i] = np.sum(curr_img[~np.isnan(curr_img) & ~np.isinf(curr_img)])\n",
    "    cal_ob[i]= np.sum(curr_ob[~np.isnan(curr_ob) & ~np.isinf(curr_ob)])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:24:49.682002Z",
     "start_time": "2019-01-28T11:24:49.424742Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cal_spectrum_norm = -1*np.log(cal_spectrum/cal_ob)\n",
    "mycalLambda = tof2l(mycaltof)\n",
    "plt.plot(mycalLambda, -1*np.log(cal_spectrum/cal_ob))\n",
    "plt.xlim(0,8)\n",
    "plt.show()\n",
    "\n",
    "myspectrum_norm = myspectrum/np.average(myspectrum)\n",
    "plt.plot(mylambda, myspectrum)\n",
    "plt.xlim(0,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:25:00.421211Z",
     "start_time": "2019-01-28T11:25:00.138593Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# yhat = savgol_filter(y, 51, 3) # window size 51, polynomial order 3\n",
    "peaks, _ = find_peaks(cal_spectrum_norm, width=15)\n",
    "plt.plot(mycalLambda, cal_spectrum_norm)\n",
    "plt.plot(mycalLambda[peaks],cal_spectrum_norm[peaks],'x', markeredgewidth=3)\n",
    "# plt.ylim(0.8,1.02)\n",
    "plt.show()\n",
    "print(mycalLambda[peaks])\n",
    "\n",
    "peaks_th, _ = find_peaks(myspectrum_norm, width=2)\n",
    "plt.plot(mylambda, myspectrum_norm)\n",
    "plt.plot(mylambda[peaks_th],myspectrum_norm[peaks_th],'x', markeredgewidth=3, c='orange')\n",
    "# plt.ylim(0.3,1.02)\n",
    "plt.show()\n",
    "print(mylambda[peaks_th])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:25:25.985809Z",
     "start_time": "2019-01-28T11:25:22.090015Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here I try to use the BE Advanced fitting to fit single edges\n",
    "print(peaks) # here I see which are the positions of the peaks\n",
    "# plt.plot(mycalLambda[1000:], cal_spectrum_norm[1000:])\n",
    "myLastPeak = cal_spectrum_norm[1000:]\n",
    "print(peaks[-1])# position of the last peak\n",
    "# plt.plot(mycalLambda[1000:],myLastPeak)\n",
    "myrange = np.array([1000, len(cal_spectrum)-1])\n",
    "est_sigma=-1\n",
    "est_alpha=-10\n",
    "\n",
    "AdvancedBraggEdgeFitting.AdvancedBraggEdgeFitting(cal_spectrum_norm, myrange, peaks[-1], est_sigma, est_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:18:14.609357Z",
     "start_time": "2019-01-28T11:18:14.579099Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def term0(t,a2,a6):\n",
    "#     return  a2 * (t - a6)\n",
    "\n",
    "# def term1(t,a2,a5,a6):\n",
    "#     return ((a5 - a2) / 2) * (t - a6)\n",
    "\n",
    "# def term3(t,t0,sigma):\n",
    "#     return erfc(-((t-t0)/(sigma * math.sqrt(2))))\n",
    "\n",
    "# def term4(t,t0,alpha,sigma):\n",
    "#     return np.exp(-((t-t0)/alpha) + ((sigma*sigma)/(2*alpha*alpha)))\n",
    "\n",
    "# def term5(t,t0,alpha,sigma):\n",
    "#     return erfc(-((t-t0)/(sigma * math.sqrt(2))) + sigma/alpha)\n",
    "\n",
    "# #TO DO: add the option to fitt either shape (?) or not\n",
    "# def BraggEdgeShape(t,t0,alpha,sigma,a1,a2,a5,a6):\n",
    "#     return a1 + term0(t,a2,a6) + term1(t,a2,a5,a6) * (1-(term3(t,t0,sigma) - term4(t,t0,alpha,sigma)* term5(t,t0,alpha,sigma)))\n",
    "\n",
    "# def BraggEdgeShape2(t,t0,alpha,sigma,a1,a2,a5,a6):\n",
    "#     return a1 + term0(t,a2,a6) + term1(t,a2,a5,a6) * ((term3(t,t0,sigma) - term4(t,t0,alpha,sigma)* term5(t,t0,alpha,sigma)))\n",
    "\n",
    "# #I am not sure that all these steps are necessary, most likely one can also only define one and decide how many to fit: TODO understand this \n",
    "# def AdvancedBraggEdgeFittingFirstStep(t,a1,a6):\n",
    "#     return a1 + term0(t,a2_f,a6) + term1(t,a2_f,a5_f,a6) * (1-(term3(t,t0_f,sigma_f) - term4(t,t0_f,alpha_f,sigma_f)* term5(t,t0_f,alpha_f,sigma_f)))\n",
    "\n",
    "# def AdvancedBraggEdgeFittingSecondStep(t,a2,a5):\n",
    "#     return a1_f + term0(t,a2,a6_f) + term1(t,a2,a5,a6_f) * (1-(term3(t,t0_f,sigma_f) - term4(t,t0_f,alpha_f,sigma_f)* term5(t,t0_f,alpha_f,sigma_f)))\n",
    "\n",
    "# def AdvancedBraggEdegFittingThirdStep(t,t0,sigma,alpha):\n",
    "#     return a1_f + term0(t,a2_f,a6_f) + term1(t,a2_f,a5_f,a6_f) * (1-(term3(t,t0,sigma) - term4(t,t0,alpha,sigma)* term5(t,t0,alpha,sigma)))\n",
    "\n",
    "# def AdvancedBraggEdegFittingFourthStep(t,a1,a2,a5,a6):\n",
    "#     return a1 + term0(t,a2,a6) + term1(t,a2,a5,a6) * (1-(term3(t,t0_f,sigma_f) - term4(t,t0_f,alpha_f,sigma_f)* term5(t,t0_f,alpha_f,sigma_f)))\n",
    "\n",
    "# def AdvancedBraggEdegFittingFifthStep(t,t0,sigma,alpha): #this is just the same as the third\n",
    "#     return a1_f + term0(t,a2_f,a6_f) + term1(t,a2_f,a5_f,a6_f) * (1-(term3(t,t0,sigma) - term4(t,t0,alpha,sigma)* term5(t,t0,alpha,sigma)))\n",
    "\n",
    "# def AdvancedBraggEdegFittingAll(t,t0,sigma,alpha,a1,a2,a5,a6):\n",
    "#     return a1 + term0(t,a2,a6) + term1(t,a2,a5,a6) * (1-(term3(t,t0,sigma) - term4(t,t0,alpha,sigma)* term5(t,t0,alpha,sigma)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-28T11:22:40.403379Z",
     "start_time": "2019-01-28T11:22:40.065194Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def AdvancedBraggEdgeFitting(myspectrum, myrange, est_pos, est_sigma, est_alpha):\n",
    "    \n",
    "#     #get the part of the spectrum that I want to fit\n",
    "# #     mybragg = -1*np.log(myspectrum[myrange[0]:myrange[1]]/np.max(myspectrum[myrange[0]:myrange[1]]))\n",
    "# #     mybragg = mybragg/np.max(mybragg)# iniziamo senza rumore aggiunto\n",
    "#     mybragg= myspectrum[myrange[0]:myrange[1]]\n",
    "#     plt.figure\n",
    "#     plt.plot(mybragg)\n",
    "    \n",
    "#     #first step: estimate the linear function before and after the Bragg Edge\n",
    "    \n",
    "#     est_pos=est_pos-myrange[0]\n",
    "#     t=np.linspace(0,np.size(mybragg)-1,np.size(mybragg))\n",
    "#     t_before= t[0:est_pos-int(est_pos*0.1)]\n",
    "#     bragg_before=mybragg[0:est_pos-int(est_pos*0.1)]\n",
    "#     t_after= t[est_pos+int(est_pos*0.1):-1]\n",
    "#     bragg_after=mybragg[est_pos+int(est_pos*0.1):-1]\n",
    "    \n",
    "#     [slope_before, interception_before] = np.polyfit(t_before, bragg_before, 1)\n",
    "#     [slope_after, interception_after] = np.polyfit(t_after, bragg_after, 1)\n",
    "    \n",
    "#     plt.figure\n",
    "#     plt.plot(t_before,bragg_before,'.k')\n",
    "#     plt.plot(t_after,bragg_after,'.k')\n",
    "#     plt.plot(t,mybragg)\n",
    "\n",
    "#     plt.plot(t,interception_before+slope_before*t)\n",
    "#     plt.plot(t,interception_after+slope_after*t)\n",
    "    \n",
    "#     #first guess of paramters\n",
    "#     t0_f=est_pos\n",
    "#     a2_f=slope_before\n",
    "#     a5_f=slope_after\n",
    "#     a6_f=t0_f-(2*mybragg[est_pos+int(est_pos*0.25)]/(a5_f-a2_f)) # I assume edge intensity is equal to 1 as I am normalizing THAT IS NOT ALWAYS THE CASE \n",
    "#     a1_f=interception_before+a2_f*a6_f\n",
    "# #     sigma_f=-1\n",
    "# #     alpha_f=-10\n",
    "\n",
    "#     sigma_f = est_sigma\n",
    "#     alpha_f = est_alpha\n",
    "#     # method='trust_exact'\n",
    "#     # method='nelder' #not bad\n",
    "#     # method='differential_evolution' # needs bounds\n",
    "#     # method='basinhopping' # not bad\n",
    "#     # method='lmsquare' # this should implement the Levemberq-Marquardt but it says Nelder-Mead method (which should be Amoeba)\n",
    "#     method ='least_squares' # default and it implements the Levenberg-Marquardt\n",
    "    \n",
    "\n",
    "#     gmodel = Model(AdvancedBraggEdegFittingAll)\n",
    "    \n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['alpha'].vary = False\n",
    "#     params['sigma'].vary = False\n",
    "#     params['t0'].vary = False\n",
    "#     params['a2'].vary= False\n",
    "#     params['a5'].vary = False\n",
    "    \n",
    "    \n",
    "#     result1 = gmodel.fit(mybragg, params, t=t, method=method, nan_policy='propagate')\n",
    "#     print(result1.fit_report())\n",
    "    \n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result1.init_fit, 'k--')\n",
    "#     plt.plot(t, result1.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "    \n",
    "#     a1_f=result1.best_values.get('a1')\n",
    "#     a6_f=result1.best_values.get('a6')\n",
    "    \n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['alpha'].vary = False\n",
    "#     params['sigma'].vary = False\n",
    "#     params['t0'].vary = False\n",
    "#     params['a1'].vary= False\n",
    "#     params['a6'].vary = False\n",
    "        \n",
    "\n",
    "#     result2 = gmodel.fit(mybragg, params, t=t, method=method, nan_policy='propagate')\n",
    "#     print(result2.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result2.init_fit, 'k--')\n",
    "#     plt.plot(t, result2.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "\n",
    "#     a2_f = result2.best_values.get('a2')\n",
    "#     a5_f = result2.best_values.get('a5')\n",
    "    \n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['a2'].vary = False\n",
    "#     params['a5'].vary = False\n",
    "#     params['a1'].vary= False\n",
    "#     params['a6'].vary = False\n",
    "#     params['sigma'].vary= False\n",
    "#     params['alpha'].vary = False\n",
    "\n",
    "\n",
    "#     result3=gmodel.fit(mybragg, params, t=t, method=method, nan_policy='propagate')\n",
    "#     print(result3.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result3.init_fit, 'k--')\n",
    "#     plt.plot(t, result3.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "    \n",
    "#     t0_f=result3.best_values.get('t0')\n",
    "# #     sigma_f=result3.best_values.get('sigma')\n",
    "# #     alpha_f=result3.best_values.get('alpha')\n",
    "\n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['a2'].vary = False\n",
    "#     params['a5'].vary = False\n",
    "#     params['a1'].vary= False\n",
    "#     params['a6'].vary = False\n",
    "# #     params['t0'].vary= False\n",
    "\n",
    "#     result4=gmodel.fit(mybragg, params, t=t, nan_policy='propagate',method=method)\n",
    "                       \n",
    "\n",
    "\n",
    "#     print(result4.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result4.init_fit, 'k--')\n",
    "#     plt.plot(t, result4.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "    \n",
    "#     sigma_f=result4.best_values.get('sigma')\n",
    "#     alpha_f=result4.best_values.get('alpha')\n",
    "#     t0_f=result4.best_values.get('t0')\n",
    "    \n",
    "    \n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['t0'].vary = False\n",
    "#     params['sigma'].vary = False\n",
    "#     params['alpha'].vary= False\n",
    "    \n",
    "    \n",
    "#     result5 = gmodel.fit(mybragg, params, t=t, nan_policy='propagate', method=method)\n",
    "#     print(result5.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result5.init_fit, 'k--')\n",
    "#     plt.plot(t, result5.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "    \n",
    "#     a1_f =result5.best_values.get('a1')\n",
    "#     a2_f = result5.best_values.get('a2')\n",
    "#     a5_f = result5.best_values.get('a5')\n",
    "#     a6_f = result5.best_values.get('a6')\n",
    "\n",
    "# #     t0_f=result5.best_values.get('t0')\n",
    "# #     sigma_f=result5.best_values.get('sigma')\n",
    "# #     alpha_f=result5.best_values.get('alpha')\n",
    "\n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     params['a2'].vary = False\n",
    "#     params['a5'].vary = False\n",
    "#     params['a1'].vary= False\n",
    "#     params['a6'].vary = False\n",
    "    \n",
    "#     result6= gmodel.fit(mybragg, params, t=t, nan_policy='propagate', method=method)\n",
    "\n",
    "\n",
    "\n",
    "# #     result6=gmodel6.fit(mybragg,t=t, t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f, nan_policy='propagate', method=method)\n",
    "    \n",
    "#     print(result6.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result6.init_fit, 'k--')\n",
    "#     plt.plot(t, result6.best_fit, 'r-')\n",
    "#     plt.show()\n",
    "\n",
    "#     t0_f=result6.best_values.get('t0')\n",
    "#     sigma_f=result6.best_values.get('sigma')\n",
    "#     alpha_f=result6.best_values.get('alpha')\n",
    "\n",
    "#     params = gmodel.make_params(t0=t0_f,sigma=sigma_f, alpha=alpha_f, a1=a1_f, a2=a2_f, a5=a5_f, a6=a6_f)\n",
    "#     result7 = gmodel.fit(mybragg, params, t=t, nan_policy='propagate', method=method)\n",
    "    \n",
    "#     print(result7.fit_report())\n",
    "#     plt.figure\n",
    "#     plt.plot(t, mybragg, 'b-')\n",
    "#     plt.plot(t, result7.init_fit, 'k--')\n",
    "#     plt.plot(t, result7.best_fit, 'r-')\n",
    "#     plt.plot(t[t0_f], mybragg[t0_f],'ok')\n",
    "#     plt.show()\n",
    "    \n",
    "#     t0_f=result7.best_values.get('t0')\n",
    "#     sigma_f=result7.best_values.get('sigma')\n",
    "#     alpha_f=result7.best_values.get('alpha')\n",
    "#     a1_f =result7.best_values.get('a1')\n",
    "#     a2_f = result7.best_values.get('a2')\n",
    "#     a5_f = result7.best_values.get('a5')\n",
    "#     a6_f = result7.best_values.get('a6')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I will then fit the calculated TOF to the theoretical lambda, x= mylambda y=mycaltof "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T09:03:28.087792Z",
     "start_time": "2019-01-25T09:03:27.855222Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.polyfit(mylambda[peaks_th[3:]],mycaltof[peaks[:]],1) # here I have to select which peaks to be used\n",
    "print(z)\n",
    "print(mycalLambda[peaks[:]])\n",
    "print(mylambda[peaks_th[3:]])\n",
    "\n",
    "\n",
    "plt.plot( mylambda[peaks_th[3:]],mycaltof[peaks[0:6]],'ob')\n",
    "plt.plot( mylambda, mytof,'-r')\n",
    "plt.plot(mylambda, mylambda*z[0]+z[1],'-g')\n",
    "plt.xlim(1,5)\n",
    "plt.xlabel('wavelength theoretical [A]')\n",
    "plt.ylabel('ToF measured [s]')\n",
    "# plt.ylim(0.0,0.03)\n",
    "plt.legend(['calibration points','theoretical curve', 'fit'])\n",
    "plt.title('Calibration plot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T09:03:34.462456Z",
     "start_time": "2019-01-25T09:03:34.459118Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T0 = z[1]\n",
    "L = (z[0]*h/m)/1e-10\n",
    "print(T0,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "145px",
    "left": "2066.5px",
    "right": "132.333px",
    "top": "141px",
    "width": "762px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
